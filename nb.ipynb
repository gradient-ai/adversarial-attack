{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TensorFlow implementation of the MobileNetV2 model: Adversarial attack demo part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# Loading ImageNet labels\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also define helper functions to preprocess the image and to extract labels from the probability vector returned by model.predict()\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def preprocess(image):\n",
    "                      image = tf.cast(image, tf.float32)\n",
    "                      image = tf.image.resize(image, (224, 224))\n",
    "                      image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "                      image = image[None, ...]\n",
    "                      return image\n",
    "\n",
    "def get_imagenet_label(probs):\n",
    "     return decode_predictions(probs, top=1)[0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The image that we are going to be using is that of a panda, since pandas are the poster-boys of the adversarial attack world. (The first paper showed an adversarial attack with an image of a panda and since then most of the articles written on adversarial attacks have been using this image). Let's load the image, preprocess it and get the class.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_raw = tf.io.read_file(\"panda.jpeg\")\n",
    "image = tf.image.decode_image(image_raw)\n",
    "image = preprocess(image)\n",
    "image_probs = pretrained_model.predict(image)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image[0] * 0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
    "_, image_class, class_confidence = get_imagenet_label(image_probs)\n",
    "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![panda_pred](https://blog.paperspace.com/content/images/2022/11/panda_pred.png)\n",
    "\n",
    "The image is classified as \"giant panda\" with 86.27% confidence.\n",
    "\n",
    "Let's create the perturbations by taking the gradients of the loss wrt original image. These perturbations will then be added to the original image itself.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = pretrained_model(input_image)\n",
    "    loss = loss_function(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad,gradient"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also visualize this.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the input label of the image.\n",
    "class_idx = 388 # index of the giant_panda class\n",
    "label = tf.one_hot(class_idx, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "perturbations,gradient = create_adversarial_pattern(image, label)\n",
    "plt.imshow(perturbations[0] * 0.5 + 0.5); "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![noise](https://blog.paperspace.com/content/images/2022/11/noise.png)\n",
    "\n",
    "Deciding the right Îµ value beforehand is quite tricky. Therefore, we'll experiment with multiple values.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons = [0, 0.01,0.03,0.1, 0.15,0.3]\n",
    "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Original Image')\n",
    "                for eps in epsilons]\n",
    "for i, eps in enumerate(epsilons):\n",
    "    adv_x = image + eps*perturbations\n",
    "    image = tf.clip_by_value(adv_x, -1, 1)\n",
    "    _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n",
    "    \n",
    "    axs[pos[i][0], pos[i][1]].imshow(image[0]*0.5+0.5)\n",
    "    axs[pos[i][0], pos[i][1]].set_title('{} \\n {} : {:.2f}%'.format(descriptions[i],label, confidence*100))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![adv_attack](https://blog.paperspace.com/content/images/2022/11/adv_attack.png)\n",
    "\n",
    "As we increase the epsilon value, the misclassification increases as identified by the class and confidence. Also, the image looks more and more perturbed. As expected,there seems to be a trade-off between the two."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}